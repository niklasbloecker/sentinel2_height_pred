{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "roVkTXRWKR3_"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy matplotlib scikit-image plotly tensorflow torch pandas xgboost scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z_M9bx1kd_Zl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from os import listdir\n",
        "import plotly.express as px\n",
        "import skimage\n",
        "from skimage.measure import block_reduce\n",
        "import pandas as pd\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from pathlib import Path\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQm1zvC79OWu"
      },
      "source": [
        "## Load and extract data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Private Test Image & Load"
      ],
      "metadata": {
        "id": "I2KmjNBjqMEp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This notebook here is the cleaned-up version with the sole goal of loading & predicting the (private) test image.\n",
        "#The training of the model that is loaded here is done in the training notebook."
      ],
      "metadata": {
        "id": "3poEGepkFjoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Private Test Image - replace path if other image to be predicted\n",
        "!wget -O private_test_image_reduced.npy \"https://uni-muenster.sciebo.de/s/Ye3GpOyPj0rCeTh/download?path=%2F&files=private_test_image_reduced.npy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maAClSu3VA8P",
        "outputId": "996386ad-566c-478a-8aa9-4818153d6baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-04 13:46:06--  https://uni-muenster.sciebo.de/s/Ye3GpOyPj0rCeTh/download?path=%2F&files=private_test_image_reduced.npy\n",
            "Resolving uni-muenster.sciebo.de (uni-muenster.sciebo.de)... 128.176.1.2\n",
            "Connecting to uni-muenster.sciebo.de (uni-muenster.sciebo.de)|128.176.1.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335544448 (320M) [application/octet-stream]\n",
            "Saving to: ‘private_test_image_reduced.npy’\n",
            "\n",
            "private_test_image_ 100%[===================>] 320.00M  19.1MB/s    in 18s     \n",
            "\n",
            "2023-07-04 13:46:25 (17.9 MB/s) - ‘private_test_image_reduced.npy’ saved [335544448/335544448]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Image in NP Arrays, transpose axis correctly\n",
        "private_test = np.array([np.load(Path(f'private_test_image_reduced.npy'))]).transpose(2,3,1,0))"
      ],
      "metadata": {
        "id": "Pbd9WJxsVMIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape test image to remove additional dimension\n",
        "X, Y, C, N = private_test.shape\n",
        "private_test = private_test.reshape(X,Y,-1)"
      ],
      "metadata": {
        "id": "0eb4ZU2SVdRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Cropped Images & Save Them in DF"
      ],
      "metadata": {
        "id": "CHxXwP-JqUcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Produce cropped images as seen in image preprocessing for Model Training - adjust to include all pixels instead of just keypoints\n",
        "\n",
        "CROPPING_OFFSET = 2 # Defines the pixel offset in every direction\n",
        "\n",
        "# Padding images to allow cropping of edge values\n",
        "padding_tuple = ((CROPPING_OFFSET,CROPPING_OFFSET), (CROPPING_OFFSET,CROPPING_OFFSET), (0,0))\n",
        "images_pad = np.pad(private_test, padding_tuple) # Padding space is filled with zero values\n",
        "\n",
        "#keypoints = masks.nonzero() # Get coordinates of measured height values\n",
        "#keypoints_val = masks[keypoints] # Get measured height values\n",
        "\n",
        "images_crop = []\n",
        "\n",
        "for i in range(2, X+CROPPING_OFFSET):\n",
        "  for j in range(2, Y+CROPPING_OFFSET):\n",
        "    image_crop = images_pad[i-CROPPING_OFFSET : i+CROPPING_OFFSET+1, j-CROPPING_OFFSET: j+CROPPING_OFFSET+1,:]\n",
        "  #print(f\"X:{x} Y:{y} | Crop X start:{x-CROPPING_OFFSET} end:{x+CROPPING_OFFSET+1} Y start:{y-CROPPING_OFFSET} end:{y+CROPPING_OFFSET+1}\")\n",
        "\n",
        "    images_crop.append([i,j,image_crop])\n",
        "\n",
        "images_crop = pd.DataFrame(images_crop, columns=[\"x\",\"y\",\"image\"])"
      ],
      "metadata": {
        "id": "lXf6R20vVtxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create MemMap, Save Cropped Images in NumpyArray, and Predict Height Values"
      ],
      "metadata": {
        "id": "Ft0TBLvvqZm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create MemMap to enable step-by-step loading of cropped images into MemMap - otherwise not enough RAM\n",
        "map_private_image_crops = np.memmap('map_private_image_crops.dat', dtype='int16', mode='w+', shape=(X*Y,5,5,C))"
      ],
      "metadata": {
        "id": "ep41eSGYU18X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step-by-step loading into MemMap\n",
        "for i in range(X*Y):\n",
        "  map_private_image_crops[i] = np.array(list(images_crop.image[i]))"
      ],
      "metadata": {
        "id": "o6PyRmQPXYqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load MemMap into normal NPArray - only transfer was problematic for 4k * 4k picture\n",
        "private_image_crops = map_private_image_crops"
      ],
      "metadata": {
        "id": "Ezo_bDWO6vt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get dimensions of NP Array for reshape - Z is X*Y, A and B are Crop Image size 5, C is amount of colour bands\n",
        "Z, A, B, C = private_image_crops.shape\n",
        "private_image_crops = private_image_crops.reshape(Z, -1)"
      ],
      "metadata": {
        "id": "p5xcxU3d652p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now apply model to get predictions for entire picture, then reshape into X * Y * Prediction\n",
        "xgb_model_prediction = XGBRegressor()\n",
        "xgb_model_prediction.load_model(\"model_xgb_crop_v1.json\") #use if json file is on local fs\n",
        "#drive.mount('/content/drive') - #use if model on Google Drive\n",
        "#xgb_model_prediction.load_model('/content/drive/My Drive/model_xgb_crop_v1.json')"
      ],
      "metadata": {
        "id": "I83EPJRYXf2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0dccc3-2c2b-410d-ef57-e73ef812380a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predict height values for tets image\n",
        "private_image_pred = xgb_model_prediction.predict(private_image_crops)"
      ],
      "metadata": {
        "id": "3Z-PWR3KFa7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reshape Predictions into Correct Form (4096x4096x1) and Save Them in .npy file"
      ],
      "metadata": {
        "id": "2RGFrvK-qp9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Reshape preds from flattened NP Array to Array with dimensions 1 * X * Y\n",
        "private_image_pred = private_image_pred.reshape(-1,4096,4096)"
      ],
      "metadata": {
        "id": "dvfQz6P-IB6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Outlier detection and Adjustment - some predictions < 0, which is impossible due to nature of measurements (height above ground) - Fix: Set negative values to 0\n",
        "private_image_pred = private_image_pred.clip(min=0)"
      ],
      "metadata": {
        "id": "xE7kp1WMrqRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Predictions in .npy file for upload\n",
        "np.save(\"private_test_image_predictions\", private_image_pred)"
      ],
      "metadata": {
        "id": "L9oIw-VWLo8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizations of the predictions are kept in the backup notebook, as the backup notebook was our working notebook for the XGB model."
      ],
      "metadata": {
        "id": "XkV73khGFMlo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dU2GxAhVdgY6",
        "DeUiSwZeFsdF",
        "uB5lMkTqZqbv",
        "I2KmjNBjqMEp",
        "CHxXwP-JqUcT",
        "Ft0TBLvvqZm9",
        "2RGFrvK-qp9v"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}